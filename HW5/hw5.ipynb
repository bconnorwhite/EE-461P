{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">EE 461P: Data Science Principles</p>\n",
    "# <p style=\"text-align: center;\">Assignment 5</p>\n",
    "## <p style=\"text-align: center;\">Total points: 40</p>\n",
    "## <p style=\"text-align: center;\">Due: Thursday, November 30th, submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group.  \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Ensembles (1+12+2 = 15pts)\n",
    "In this question, we will compare performance of different ensemble methods: [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [XGBoost](http://xgboost.readthedocs.io/en/latest/).  Note that you have to install xgboost package in addition to scikit-learn.  You can see installation guides [here](http://xgboost.readthedocs.io/en/latest/build.html).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Two  datasets are provided for this problem. For **each of the datasets ((X1.csv, y1.csv), (X2.csv, y2.csv))**, do the following:\n",
    "\n",
    "1. Load the data and partition it into features (X) and the target label (y) for classification task. Then, use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42.\n",
    "\n",
    "2. Build a classifier using [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), and [XGBoost](http://xgboost.readthedocs.io/en/latest/), respectively, and answer the following for each classifier.\n",
    "\n",
    " - Mention any design choices (with reasoning/justification) that you made, e.g. the hyperparameters considered for each classifier.\n",
    " - Report the mean error rate (fraction of incorrect labels) and the confusion matrix on test data. <br>\n",
    " - Report the feature importance and time of execution (training and predicting times).\n",
    "\n",
    "3. Compare the three classifiers for the two different datasets ((X1.csv, y1.csv), (X2.csv, y2.csv)) in terms of the misclassification rate.  What are the characteristics of the dataset and the classifiers that resulted in somewhat different comparative results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [pd.read_csv(\"X1.csv\"), pd.read_csv(\"X2.csv\")]\n",
    "y = [pd.read_csv(\"y1.csv\"), pd.read_csv(\"y2.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [[],[]]\n",
    "X_test = [[],[]]\n",
    "y_train = [[],[]]\n",
    "y_test = [[],[]]\n",
    "\n",
    "X_train[0], X_test[0], y_train[0], y_test[0] = train_test_split(X[0], y[0], test_size=0.33, random_state=42)\n",
    "X_train[1], X_test[1], y_train[1], y_test[1] = train_test_split(X[1], y[1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, n):\n",
    "    start = time.time()\n",
    "    model.fit(X_train[n], y_train[n])\n",
    "    return model, (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, n):\n",
    "    start = time.time()\n",
    "    y_preds = model.predict(X_test[n])\n",
    "    return y_preds, (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "        min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None,\n",
    "        min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0,\n",
    "        warm_start=False, class_weight=None)\n",
    "gbc = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100,\n",
    "        subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "        max_depth=3, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0,\n",
    "        max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "        colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = [\"Random Forest Classifier\", \"Gradient Boosting Classifier\", \"XGBoost\"]\n",
    "models = [rfc, gbc, xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set  1  -  Random Forest Classifier =================\n",
      "Training Time:  0.09690713882446289\n",
      "Feature Importances:  [  1.38209466e-01   2.34387999e-02   1.36209609e-04   1.65436724e-02\n",
      "   4.28460042e-02   0.00000000e+00   3.25945442e-02   0.00000000e+00\n",
      "   0.00000000e+00   1.48585171e-03   5.11528737e-02   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.18759142e-03   3.05401981e-02\n",
      "   0.00000000e+00   0.00000000e+00   1.05927647e-01   0.00000000e+00\n",
      "   0.00000000e+00   2.91087066e-01   1.95915206e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   4.15098390e-02   2.34250303e-02\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "Predict Time:  0.0034189224243164062\n",
      "RFC Percent Correct:  0.500991735537\n",
      "Confusion Matrix:  [[1358  342]\n",
      " [ 184 1416]]\n",
      "\n",
      "Set  1  -  Gradient Boosting Classifier =================\n",
      "Training Time:  3.273698091506958\n",
      "Feature Importances:  [ 0.12359967  0.01328609  0.02539225  0.01317231  0.02086548  0.01020775\n",
      "  0.02188709  0.02318999  0.00467864  0.02026064  0.00854145  0.01458274\n",
      "  0.01009431  0.01383859  0.0102437   0.00695808  0.00499981  0.0078938\n",
      "  0.15815392  0.00844881  0.00779071  0.13244914  0.24443425  0.01840551\n",
      "  0.00890761  0.01281572  0.01109688  0.01609751  0.02319681  0.00451074]\n",
      "Predict Time:  0.0074939727783203125\n",
      "RFC Percent Correct:  0.499972451791\n",
      "Confusion Matrix:  [[1480  220]\n",
      " [ 173 1427]]\n",
      "\n",
      "Set  1  -  XGBoost =================\n",
      "Training Time:  16.748476028442383\n",
      "Feature Importances:  [ 0.06025061  0.02998226  0.02958174  0.0275791   0.02677805  0.03192768\n",
      "  0.02992504  0.02609143  0.02254391  0.02860903  0.02912399  0.02700692\n",
      "  0.0234594   0.0282085   0.02586256  0.0323282   0.02603422  0.02929565\n",
      "  0.07238084  0.02752189  0.02632031  0.07060708  0.07404017  0.02391715\n",
      "  0.02735023  0.02923843  0.02752189  0.0282085   0.03118384  0.02712136]\n",
      "Predict Time:  0.34784603118896484\n",
      "RFC Percent Correct:  0.500045913682\n",
      "Confusion Matrix:  [[1527  173]\n",
      " [ 118 1482]]\n",
      "\n",
      "Set  2  -  Random Forest Classifier =================\n",
      "Training Time:  0.37833404541015625\n",
      "Feature Importances:  [ 0.          0.          0.          0.05571409  0.06400119  0.10556154\n",
      "  0.05310405  0.10294685  0.04726098  0.2009072   0.          0.11332271\n",
      "  0.          0.04161565  0.          0.07828738  0.01965206  0.\n",
      "  0.11762631  0.        ]\n",
      "Predict Time:  0.005563974380493164\n",
      "RFC Percent Correct:  0.502279522498\n",
      "Confusion Matrix:  [[600 254]\n",
      " [118 678]]\n",
      "\n",
      "Set  2  -  Gradient Boosting Classifier =================\n",
      "Training Time:  3.57614803314209\n",
      "Feature Importances:  [ 0.03584561  0.00159719  0.00168504  0.07582648  0.06604653  0.04129662\n",
      "  0.04959452  0.07841117  0.02868397  0.12627242  0.04517815  0.08058069\n",
      "  0.          0.07592878  0.          0.09525197  0.06244134  0.00640996\n",
      "  0.09112298  0.03782659]\n",
      "Predict Time:  0.016571044921875\n",
      "RFC Percent Correct:  0.499978696051\n",
      "Confusion Matrix:  [[762  92]\n",
      " [ 64 732]]\n",
      "\n",
      "Set  2  -  XGBoost =================\n",
      "Training Time:  7.4078309535980225\n",
      "Feature Importances:  [ 0.04821619  0.0289686   0.02585788  0.05667347  0.05881209  0.0608535\n",
      "  0.05365996  0.06017303  0.05570137  0.06211723  0.05521532  0.05472927\n",
      "  0.03577331  0.06124235  0.03032954  0.06493632  0.05385438  0.02751045\n",
      "  0.05949256  0.04588315]\n",
      "Predict Time:  0.06702709197998047\n",
      "RFC Percent Correct:  0.499978696051\n",
      "Confusion Matrix:  [[788  66]\n",
      " [ 38 758]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for set in range(0, 2):\n",
    "    for m in range(0, len(models)):\n",
    "        print(\"Set \", set+1, \" - \", titles[m], \"=================\")\n",
    "        model, elapsed = train(models[m], set)\n",
    "        print(\"Training Time: \", elapsed)\n",
    "        print(\"Feature Importances: \", model.feature_importances_)\n",
    "        y_preds, elapsed = predict(model, set)\n",
    "        print(\"Predict Time: \", elapsed)\n",
    "        print(\"RFC Percent Correct: \", np.mean(np.array(y_test[set]) != np.array(y_preds)))\n",
    "        print(\"Confusion Matrix: \", confusion_matrix(y_test[set], y_preds))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Visualization using Bokeh (10 pts)\n",
    "\n",
    "In this problem, you'll build an interactive visualization. Bokeh is a Python interactive visualization library that targets modern web browsers for presentation. For more information on Bokeh, see http://bokeh.pydata.org/en/latest/. The problem statement is as follows:\n",
    "\n",
    "Using the \"nbasalariesfull.csv\" data set from HMK4, your goal is to build a Bokeh visualization which allows the user to explore how salary (on a log scale) varies with points per game (PSG) and age. You will create a visualization that allows the user to toggle the X axis of a scatter plot between PSG and age, with the y-axis always being log Salary. Also add the hover tool so that if the user hovers over a datapoint in the plot a window pops up that shows the player name, team, position, salary, and the current x variable (PSG or age) depending on the current tab.  Color each point according to a player's position and provide a legend for the colors. Add the ability to Zoom in/out.  Add slight horizontal jitter to a player's age.\n",
    "\n",
    "Hints: \n",
    "1. see: http://bokeh.pydata.org/en/latest/docs/user_guide/tools.html#basic-tooltips for hover and zoom tool examples.\n",
    "2. See: http://bokeh.pydata.org/en/latest/docs/reference/plotting.html. Look for the scatter API.\n",
    "3. See: http://bokeh.pydata.org/en/0.10.0/docs/user_guide/styling.html#labels. For labeling axes.\n",
    "4. See: https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html  for how to use jitter transform\n",
    "5. Use output_notebook() from Bokeh to output the plot to your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "unexpected attribute 'colors' to Circle, similar attributes are line_color or fill_color",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bf59c7c35e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Age Tab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m950\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhover1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoxZoomTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logSalary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mtab1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPanel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfakesource\u001b[0m in \u001b[0;36mcircle\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n",
      "\u001b[0;32mc:\\users\\kyle\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bokeh\\plotting\\helpers.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mmglyph_ca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mglyph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_glyph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglyphclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglyph_ca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mnsglyph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_glyph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglyphclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsglyph_ca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0msglyph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_glyph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglyphclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msglyph_ca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\kyle\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bokeh\\plotting\\helpers.py\u001b[0m in \u001b[0;36m_make_glyph\u001b[0;34m(glyphclass, kws, extra)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0mkws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mkws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mglyphclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\kyle\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bokeh\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0mdefault_theme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\kyle\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bokeh\\core\\has_props.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **properties)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\kyle\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bokeh\\core\\has_props.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             raise AttributeError(\"unexpected attribute '%s' to %s, %s attributes are %s\" %\n\u001b[0;32m--> 271\u001b[0;31m                 (name, self.__class__.__name__, text, nice_join(matches)))\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: unexpected attribute 'colors' to Circle, similar attributes are line_color or fill_color"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.models import CustomJS, ColumnDataSource, HoverTool, BoxZoomTool\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "data = pd.read_csv(\"nbasalariesfull.csv\")\n",
    "data[\"logsalary\"] = data.SALARY.apply(np.log)\n",
    "\n",
    "# Data Source\n",
    "source = ColumnDataSource(data=dict(\n",
    "    age=data['Age'],\n",
    "    psg=data['PSG'],\n",
    "    logSalary=data['logsalary'],\n",
    "    playerName = data['Player'],\n",
    "    team = data['Tm'],\n",
    "    position = data['Pos'],\n",
    "    salary = data['SALARY']\n",
    "))\n",
    "\n",
    "# Hover1\n",
    "hover1 = HoverTool(tooltips = [\n",
    "    (\"player name\", \"@playerName\"),\n",
    "    (\"team\", \"@team\"),\n",
    "    (\"position\", \"@position\"),\n",
    "    (\"salary\", \"@salary\"),\n",
    "    (\"age\", \"@age\"),\n",
    "])\n",
    "\n",
    "# Hover2\n",
    "hover2 = HoverTool(tooltips = [\n",
    "    (\"player name\", \"@playerName\"),\n",
    "    (\"team\", \"@team\"),\n",
    "    (\"position\", \"@position\"),\n",
    "    (\"salary\", \"@salary\"),\n",
    "    (\"psg\", \"@psg\"),\n",
    "])\n",
    "\n",
    "#colors = [\"#%02x%02x%02x\" % (r, g, 150) for r, g in zip(np.floor(50+2*x), np.floor(30+2*y))]\n",
    "\n",
    "# Age Tab\n",
    "p1 = figure(plot_width=950, plot_height=500, tools=[hover1, BoxZoomTool()])\n",
    "p1.circle(x=jitter('age', width=0.6, range=plot.x_range), \\\n",
    "          y='logSalary', source=source, size=4, colors='age', legend='position')\n",
    "tab1 = Panel(child=p1, title=\"age\")\n",
    "\n",
    "# PSG Tab\n",
    "p2 = figure(plot_width=950, plot_height=500, tools=[hover2, BoxZoomTool()])\n",
    "p2.circle(x='psg', y='logSalary', source=source, size=4, color='position', legend='position')\n",
    "tab2 = Panel(child=p2, title=\"PSG\")\n",
    "\n",
    "\n",
    "# Plot Label\n",
    "p1.yaxis.axis_label = \"Log Salary\"\n",
    "p1.xaxis.axis_label = \"Age\"\n",
    "p2.yaxis.axis_label = \"Log Salary\"\n",
    "p2.xaxis.axis_label = \"PSG\"\n",
    "plot.legend.orientation = \"horizontal\"\n",
    "\n",
    "\n",
    "tabs = Tabs(tabs=[ tab1, tab2 ])\n",
    "show(tabs)\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Clustering (15 pts)\n",
    "\n",
    "## Part a\n",
    "\n",
    "This problem explores scaling, clustering, and one method of evaluating the quality of a clustering. You will also examine some of the issues in k-means clustering, and some ways to mitigate these problems. You will be using Fisher's Iris dataset available in sklearn.\n",
    "\n",
    "We wish to cluster the dataset to find any similar groups of flowers. However, we are not certain that the scales of the various features are well-suited for clustering. We will use scipy's k-means clustering package for this problem.\n",
    "\n",
    "When calculating the cluster purity, use the following equations:\n",
    "\n",
    "$ClassPurity(C_i$) = $\\frac{1}{|C_i|}\\max_j(|C_i|_{class=j})$\n",
    "\n",
    "$NetPurity$ = $\\sum_{i=1}^k\\frac{|C_i|}{|D|}purity(C_i)$\n",
    "\n",
    "where $|C_i|$ is the total number of data points assigned to cluster $C_i$, $|C_i|_{class=j}$ is the number of data points from class $j$ assigned to cluster $C_i$ and $D$ refers to the whole dataset.\n",
    "\n",
    "1. Cluster the data into 4 clusters, using K-means and calculate the NetPurity for your solution.\n",
    "2. Now linearly scale each feature so that the values range from 0 to 1. Cluster the data using the k-means algorithm (as before), and calculate the cluster purity for the clustering. Report the calculations you used to scale the features, as well as the NetPurity.\n",
    "3. Linearly scale the original dataset features so that the distribution of values for each feature has a mean of 0 and a standard deviation of 1. Cluster the data as before, and report the NetPurity obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pml' has no attribute 'unsupervised'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f0afef73d9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsupervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusteredDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_purity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pml' has no attribute 'unsupervised'"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=4, random_state=0)\n",
    "km.fit(X)\n",
    "\n",
    "import pml\n",
    "pml.unsupervised.clustering.ClusteredDataSet(X,y).calculate_purity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calc net purity here kyle ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22222222,  0.625     ],\n",
       "       [ 0.16666667,  0.41666667],\n",
       "       [ 0.11111111,  0.5       ],\n",
       "       [ 0.08333333,  0.45833333],\n",
       "       [ 0.19444444,  0.66666667],\n",
       "       [ 0.30555556,  0.79166667],\n",
       "       [ 0.08333333,  0.58333333],\n",
       "       [ 0.19444444,  0.58333333],\n",
       "       [ 0.02777778,  0.375     ],\n",
       "       [ 0.16666667,  0.45833333],\n",
       "       [ 0.30555556,  0.70833333],\n",
       "       [ 0.13888889,  0.58333333],\n",
       "       [ 0.13888889,  0.41666667],\n",
       "       [ 0.        ,  0.41666667],\n",
       "       [ 0.41666667,  0.83333333],\n",
       "       [ 0.38888889,  1.        ],\n",
       "       [ 0.30555556,  0.79166667],\n",
       "       [ 0.22222222,  0.625     ],\n",
       "       [ 0.38888889,  0.75      ],\n",
       "       [ 0.22222222,  0.75      ],\n",
       "       [ 0.30555556,  0.58333333],\n",
       "       [ 0.22222222,  0.70833333],\n",
       "       [ 0.08333333,  0.66666667],\n",
       "       [ 0.22222222,  0.54166667],\n",
       "       [ 0.13888889,  0.58333333],\n",
       "       [ 0.19444444,  0.41666667],\n",
       "       [ 0.19444444,  0.58333333],\n",
       "       [ 0.25      ,  0.625     ],\n",
       "       [ 0.25      ,  0.58333333],\n",
       "       [ 0.11111111,  0.5       ],\n",
       "       [ 0.13888889,  0.45833333],\n",
       "       [ 0.30555556,  0.58333333],\n",
       "       [ 0.25      ,  0.875     ],\n",
       "       [ 0.33333333,  0.91666667],\n",
       "       [ 0.16666667,  0.45833333],\n",
       "       [ 0.19444444,  0.5       ],\n",
       "       [ 0.33333333,  0.625     ],\n",
       "       [ 0.16666667,  0.45833333],\n",
       "       [ 0.02777778,  0.41666667],\n",
       "       [ 0.22222222,  0.58333333],\n",
       "       [ 0.19444444,  0.625     ],\n",
       "       [ 0.05555556,  0.125     ],\n",
       "       [ 0.02777778,  0.5       ],\n",
       "       [ 0.19444444,  0.625     ],\n",
       "       [ 0.22222222,  0.75      ],\n",
       "       [ 0.13888889,  0.41666667],\n",
       "       [ 0.22222222,  0.75      ],\n",
       "       [ 0.08333333,  0.5       ],\n",
       "       [ 0.27777778,  0.70833333],\n",
       "       [ 0.19444444,  0.54166667],\n",
       "       [ 0.75      ,  0.5       ],\n",
       "       [ 0.58333333,  0.5       ],\n",
       "       [ 0.72222222,  0.45833333],\n",
       "       [ 0.33333333,  0.125     ],\n",
       "       [ 0.61111111,  0.33333333],\n",
       "       [ 0.38888889,  0.33333333],\n",
       "       [ 0.55555556,  0.54166667],\n",
       "       [ 0.16666667,  0.16666667],\n",
       "       [ 0.63888889,  0.375     ],\n",
       "       [ 0.25      ,  0.29166667],\n",
       "       [ 0.19444444,  0.        ],\n",
       "       [ 0.44444444,  0.41666667],\n",
       "       [ 0.47222222,  0.08333333],\n",
       "       [ 0.5       ,  0.375     ],\n",
       "       [ 0.36111111,  0.375     ],\n",
       "       [ 0.66666667,  0.45833333],\n",
       "       [ 0.36111111,  0.41666667],\n",
       "       [ 0.41666667,  0.29166667],\n",
       "       [ 0.52777778,  0.08333333],\n",
       "       [ 0.36111111,  0.20833333],\n",
       "       [ 0.44444444,  0.5       ],\n",
       "       [ 0.5       ,  0.33333333],\n",
       "       [ 0.55555556,  0.20833333],\n",
       "       [ 0.5       ,  0.33333333],\n",
       "       [ 0.58333333,  0.375     ],\n",
       "       [ 0.63888889,  0.41666667],\n",
       "       [ 0.69444444,  0.33333333],\n",
       "       [ 0.66666667,  0.41666667],\n",
       "       [ 0.47222222,  0.375     ],\n",
       "       [ 0.38888889,  0.25      ],\n",
       "       [ 0.33333333,  0.16666667],\n",
       "       [ 0.33333333,  0.16666667],\n",
       "       [ 0.41666667,  0.29166667],\n",
       "       [ 0.47222222,  0.29166667],\n",
       "       [ 0.30555556,  0.41666667],\n",
       "       [ 0.47222222,  0.58333333],\n",
       "       [ 0.66666667,  0.45833333],\n",
       "       [ 0.55555556,  0.125     ],\n",
       "       [ 0.36111111,  0.41666667],\n",
       "       [ 0.33333333,  0.20833333],\n",
       "       [ 0.33333333,  0.25      ],\n",
       "       [ 0.5       ,  0.41666667],\n",
       "       [ 0.41666667,  0.25      ],\n",
       "       [ 0.19444444,  0.125     ],\n",
       "       [ 0.36111111,  0.29166667],\n",
       "       [ 0.38888889,  0.41666667],\n",
       "       [ 0.38888889,  0.375     ],\n",
       "       [ 0.52777778,  0.375     ],\n",
       "       [ 0.22222222,  0.20833333],\n",
       "       [ 0.38888889,  0.33333333],\n",
       "       [ 0.55555556,  0.54166667],\n",
       "       [ 0.41666667,  0.29166667],\n",
       "       [ 0.77777778,  0.41666667],\n",
       "       [ 0.55555556,  0.375     ],\n",
       "       [ 0.61111111,  0.41666667],\n",
       "       [ 0.91666667,  0.41666667],\n",
       "       [ 0.16666667,  0.20833333],\n",
       "       [ 0.83333333,  0.375     ],\n",
       "       [ 0.66666667,  0.20833333],\n",
       "       [ 0.80555556,  0.66666667],\n",
       "       [ 0.61111111,  0.5       ],\n",
       "       [ 0.58333333,  0.29166667],\n",
       "       [ 0.69444444,  0.41666667],\n",
       "       [ 0.38888889,  0.20833333],\n",
       "       [ 0.41666667,  0.33333333],\n",
       "       [ 0.58333333,  0.5       ],\n",
       "       [ 0.61111111,  0.41666667],\n",
       "       [ 0.94444444,  0.75      ],\n",
       "       [ 0.94444444,  0.25      ],\n",
       "       [ 0.47222222,  0.08333333],\n",
       "       [ 0.72222222,  0.5       ],\n",
       "       [ 0.36111111,  0.33333333],\n",
       "       [ 0.94444444,  0.33333333],\n",
       "       [ 0.55555556,  0.29166667],\n",
       "       [ 0.66666667,  0.54166667],\n",
       "       [ 0.80555556,  0.5       ],\n",
       "       [ 0.52777778,  0.33333333],\n",
       "       [ 0.5       ,  0.41666667],\n",
       "       [ 0.58333333,  0.33333333],\n",
       "       [ 0.80555556,  0.41666667],\n",
       "       [ 0.86111111,  0.33333333],\n",
       "       [ 1.        ,  0.75      ],\n",
       "       [ 0.58333333,  0.33333333],\n",
       "       [ 0.55555556,  0.33333333],\n",
       "       [ 0.5       ,  0.25      ],\n",
       "       [ 0.94444444,  0.41666667],\n",
       "       [ 0.55555556,  0.58333333],\n",
       "       [ 0.58333333,  0.45833333],\n",
       "       [ 0.47222222,  0.41666667],\n",
       "       [ 0.72222222,  0.45833333],\n",
       "       [ 0.66666667,  0.45833333],\n",
       "       [ 0.72222222,  0.45833333],\n",
       "       [ 0.41666667,  0.29166667],\n",
       "       [ 0.69444444,  0.5       ],\n",
       "       [ 0.66666667,  0.54166667],\n",
       "       [ 0.66666667,  0.41666667],\n",
       "       [ 0.55555556,  0.20833333],\n",
       "       [ 0.61111111,  0.41666667],\n",
       "       [ 0.52777778,  0.58333333],\n",
       "       [ 0.44444444,  0.41666667]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=4, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b\n",
    "\n",
    "Run both single link and complete link hierarchical clustering algorithms on the iris dataset, and submit the two dendograms. \n",
    "\n",
    "1. For each dendogram, visually inspect it to suggest what value(s) of $k$ (between 1 and 6) seem reasonable to choose for this dataset. \n",
    "2. Do you observe any difference in the structure of the 2 dendograms? How do you explain this difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEHCAYAAABLKzaMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBcRydj/B7gIeAmP2iovAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131eedd2320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "\n",
    "single_link = linkage(y=X, method='single')\n",
    "complete_link = linkage(y=X, method='complete')\n",
    "\n",
    "dendrogram(single_link, truncate_mode='lastp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEqTkLiKSICV3EZEE/T90q+uU1voUwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131ed8114a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dendrogram(complete_link, truncate_mode='lastp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\n",
    "The single-link plot almost looks like a large, single cluster. 2 clusters could be formed from the green, and then the blue and red combined. I would say k = 1-2 for the single-link.\n",
    "\n",
    "The complete-link plot seems to have 4 clusters. The green, red, and then 2 from the first branch of the blue. I would say k = 4 for the complete-link.\n",
    "\n",
    "2)\n",
    "The single-link dendrogram has a majority of datapoints in the red cluster, while the complete-link dendrogram has more evently distributed clusters. The single-link cluster has such a large cluster of points because it expands clusters by looking at the closest point in the existing cluster, whereas complete-link looks at the furthest away point. This means that the single-link will form a long chain of closely related points, where as the complete link will for clusters where no points are too far apart from any other point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c\n",
    "\n",
    "1. What is the cost function minimised in the k-means clustering algorithm?\n",
    "2. Explain how this can be generalized to be of the form $J = \\sum_{i=1}^k n_i s_i$, where $s_i$ is the average squared (Euclidean) distance between pairs of points in cluster $i$ (every point is compared with every point - including itself - in the same cluster, so we have $n_i^2$ comparisions that are averaged over to get $s_i$), \n",
    "and $n_i$ is the total number of points in cluster $i$.\n",
    "3. What would the benefit of such a generalized expression be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Standard Expression, $J = \\sum_{i=1}^k \\sum_{x \\in S_i} ||x-\\mu_i||^2$, where \\mu_i is the mean of the points in S_i\n",
    "2. Generalized expression, \n",
    "    $J = \\sum_{i=1}^k n_i * (||x-\\mu_i||^2 /n_i)$ where n_i is the number of samples in each cluster\n",
    "    \n",
    "    $J = \\sum_{i=1}^k n_i * s_i $ where s_i is the variance within each cluster\n",
    "\n",
    "3. Benefit: $s_i$ can now be replaced with any similarity metric based on the clustering problem requirements"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
